{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyro_stocks.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JP11zestmbo-",
        "ihrML0Bwmf9n",
        "3dLne2gYPCmv",
        "0AsnqWeCBA0R",
        "mjfG3cCWlL9y",
        "DILzjmqrrMgX",
        "4CMHc01PXnfG",
        "jCndeWlYXwfm",
        "CM43F_EKXzSU",
        "BgyFQL0dX1Iz"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nw7Fs7QOqLK",
        "colab_type": "text"
      },
      "source": [
        "# CS 267A - Final Project GNN\n",
        "Use this notebook to test functions collaboratively. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbMLRQltVvVv",
        "colab_type": "text"
      },
      "source": [
        "- https://github.com/fulifeng/Temporal_Relational_Stock_Ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JVNoB1aweDE",
        "colab_type": "text"
      },
      "source": [
        "## Environment Init "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX275VV5xmYN",
        "colab_type": "text"
      },
      "source": [
        "### Stock and Relational Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c20pAMkoOo1H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "530ffcbe-ba79-4499-f689-d4ec1e3f8d14"
      },
      "source": [
        "! git clone https://github.com/fulifeng/Temporal_Relational_Stock_Ranking.git\n",
        "! tar zxvf Temporal_Relational_Stock_Ranking/data/relation.tar.gz -C Temporal_Relational_Stock_Ranking/data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Temporal_Relational_Stock_Ranking'...\n",
            "remote: Enumerating objects: 9126, done.\u001b[K\n",
            "remote: Total 9126 (delta 0), reused 0 (delta 0), pack-reused 9126\u001b[K\n",
            "Receiving objects: 100% (9126/9126), 330.30 MiB | 21.39 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n",
            "Checking out files: 100% (11376/11376), done.\n",
            "relation/\n",
            "relation/sector_industry/\n",
            "relation/sector_industry/NASDAQ_industry_ticker.json\n",
            "relation/sector_industry/NYSE_industry_ticker.json\n",
            "relation/sector_industry/NASDAQ_industry_relation.npy\n",
            "relation/sector_industry/NYSE_industry_relation.npy\n",
            "relation/wikidata/\n",
            "relation/wikidata/NASDAQ_wiki_relation.npy\n",
            "relation/wikidata/NYSE_wiki_relation.npy\n",
            "relation/wikidata/NYSE_connections.json\n",
            "relation/wikidata/NASDAQ_connections.json\n",
            "relation/wikidata/selected_wiki_connections.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwD5z6NCxqYk",
        "colab_type": "text"
      },
      "source": [
        "### Pretrained Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq5FVrSDtfdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# causes colab to crash. You'll just have to download the pretrained model at\n",
        "# https://drive.google.com/file/d/1fyNCZ62pEItTQYEBzLwsZ9ehX_-Ai3qT\n",
        "# I've uploaded it to my Google Drive and mount it to colab to acccess\n",
        "\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "# from googleapiclient.discovery import build\n",
        "# drive_service = build('drive', 'v3')\n",
        "\n",
        "# file_id = \"1fyNCZ62pEItTQYEBzLwsZ9ehX_-Ai3qT\"\n",
        "\n",
        "# import io\n",
        "# from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "# request = drive_service.files().get_media(fileId=file_id)\n",
        "# downloaded = io.BytesIO()\n",
        "# downloader = MediaIoBaseDownload(downloaded, request)\n",
        "# done = False\n",
        "# while done is False:\n",
        "#   _, done = downloader.next_chunk()\n",
        "\n",
        "# downloaded.seek(0)\n",
        "# print('Downloaded file contents are: {}'.format(downloaded.read()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNUHeaN1u2cf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72dbc31d-df89-42fa-aede-328a0d153fb3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAu1AKtQwcmr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b0346300-ddfc-4253-c8fd-f046cd398dfa"
      },
      "source": [
        "! tar zxvf drive/My\\ Drive/data/gnn_stocks/pretrain.tar.gz -C Temporal_Relational_Stock_Ranking/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar (child): drive/My Drive/data/gnn_stocks/pretrain.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVdM8kBjx13M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a1cd806-37b7-4c8f-91ba-b2767e165f9c"
      },
      "source": [
        "% cd Temporal_Relational_Stock_Ranking/training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Temporal_Relational_Stock_Ranking/training/Temporal_Relational_Stock_Ranking/training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9Ekeza7aWmm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "0bb47a84-4a3c-428a-809a-96f667bb752b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1fs0SQDXjFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61b80efc-d738-4cad-d27f-08f9c17cea9d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "evaluator.py  load_data.py  __pycache__  rank_lstm.py  relation_rank_lstm.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u9yi6EwmWrv",
        "colab_type": "text"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAXV7oyWXCbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from load_data import load_EOD_data, load_relation_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vzWIl2HX99I",
        "colab_type": "text"
      },
      "source": [
        "`python relation_rank_lstm.py -rn wikidata -l 16 -u 64 -a 0.1`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP11zestmbo-",
        "colab_type": "text"
      },
      "source": [
        "### Stock Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS9NTaQsZqUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# params\n",
        "data_path = '../data/2013-01-01'\n",
        "market_name = 'NASDAQ' # 'NASDAQ' 'NYSE'\n",
        "tickers_fname = market_name + '_tickers_qualify_dr-0.98_min-5_smooth.csv'\n",
        "steps = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_9iYJ04V06c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a3bcaa5e-d459-4dd7-854a-74cd45273fbf"
      },
      "source": [
        "# load stock data\n",
        "tickers = np.genfromtxt(os.path.join(data_path, '..', tickers_fname),\n",
        "                              dtype=str, delimiter='\\t', skip_header=False)\n",
        "\n",
        "print('#tickers selected:', len(tickers))\n",
        "eod_data, mask_data, gt_data, price_data = \\\n",
        "    load_EOD_data(data_path, market_name, tickers, steps)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#tickers selected: 1737\n",
            "single EOD data shape: (1245, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDEBF12lcGPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyivHJYOoGGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "c9b3d1c9-95c0-4e00-8ec6-157aed8e0d3e"
      },
      "source": [
        "!pip install --upgrade -q jax==0.1.57 jaxlib==0.1.37 numpyro\n",
        "!pip install yfinance\n",
        "\n",
        "import jax.numpy as np\n",
        "from jax import random\n",
        "import numpyro; numpyro.set_host_device_count(4)\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.infer import MCMC, NUTS\n",
        "assert numpyro.__version__.startswith('0.2.4')\n",
        "\n",
        "from scipy.stats import norm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.6/dist-packages (0.1.54)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.0.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.18.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.24->yfinance) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcShDmrgcrW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_ar(data, predict_len = 1):\n",
        "    \"\"\"AR Model for which parameters are calculated and not learned.\n",
        "\n",
        "    Parameters:\n",
        "    data (np.array): Array with training data\n",
        "    predict_len (int): Number of time-steps for which future prediction in needed\n",
        "\n",
        "    Returns:\n",
        "    np.array: Array with predictions of specified length \n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate psi\n",
        "    # Source: Page 7 of https://www.math.utah.edu/~zhorvath/ar1.pdf\n",
        "    num = 0\n",
        "    for i in range(1, len(data)):\n",
        "        num += data[i] * data[i-1]\n",
        "\n",
        "    denom = 0\n",
        "    for i in range(0, len(data) - 1):\n",
        "        denom += data[i] * data[i]\n",
        "\n",
        "    psi = num / denom\n",
        "\n",
        "    # Find the distribution of epsilons\n",
        "    epsilon_dist = [0]*(len(data)-1)\n",
        "    for i in range(1, len(data)):\n",
        "        epsilon_dist[i-1] = data[i] - psi * data[i - 1]\n",
        "    epsilon_dist = np.array(epsilon_dist)\n",
        "    (loc, scale) = norm.fit(epsilon_dist)\n",
        "  \n",
        "    # For prediction, sample some epsilons from the distribution\n",
        "    epsilons = numpyro.sample(\"epsilons\", dist.Normal(loc=loc, scale=scale), rng_key=random.PRNGKey(2), sample_shape=(1, predict_len))[0]\n",
        "\n",
        "    # Make the predictions\n",
        "    predictions = [0] * predict_len\n",
        "\n",
        "    y_prev = data[-1]\n",
        "    for i in range(0, predict_len):\n",
        "        y_next =  epsilons[i] + y_prev * psi\n",
        "        predictions[i] = y_next\n",
        "        y_prev = y_next\n",
        "    growth = [((predictions[i]-data[-1])/data[-1])] +[0]*(predict_len-1)\n",
        "    for i in range(1,predict_len):\n",
        "        growth[i] = (predictions[i]-predictions[i-1])/predictions[i-1]\n",
        "    return np.array(growth)\n",
        "def profit(test,truth):\n",
        "    total = [0]*len(test[0])\n",
        "    for i in range(0,len(test[0])):\n",
        "        best_buy = np.argmax(test[:,i])\n",
        "        total[i] = 100*(truth[best_buy,i]+1)\n",
        "    return total\n",
        "def get_dataset(price_data, n ,growth_data, train_size = 500, test_size = 50):\n",
        "    \n",
        "    start_point = n*train_size\n",
        "    split_point = start_point + train_size\n",
        "    final_point = split_point + test_size\n",
        "    if final_point > len(price_data[0]):\n",
        "        return len(price_data[0]) - start_point\n",
        "    train = price_data[:,start_point:split_point]\n",
        "    test = price_data[:,split_point:final_point]\n",
        "    grow = growth_data[:,split_point:final_point]\n",
        "    return train,grow\n",
        "def get_results(train,train_len = 50):\n",
        "    results = [0]*len(train)\n",
        "    for i in range(0,len(train)):\n",
        "      \n",
        "      results[i]=(calc_ar(train[i],predict_len = train_len))\n",
        "    print(\"is_it_calc?\")\n",
        "    return np.array(results)\n",
        "def total_dataset(price_data,gt_data,train_size = 50):\n",
        "    count = 0\n",
        "    actual_total = []\n",
        "    best_total = []\n",
        "    while type(get_dataset(price_data,count,gt_data))!= type(1):\n",
        "        print(\"count\",count)\n",
        "        dataset = get_dataset(price_data,count,gt_data, test_size = train_size)\n",
        "        predictions = get_results(dataset[0],train_len = train_size)\n",
        "        actual_total.append(profit(predictions,dataset[1]))\n",
        "        best_total.append(profit(dataset[1],dataset[1]))\n",
        "        count+=1\n",
        "    return actual_total, best_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oNWFzqBdlzQ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "92faa4de-7fca-4c0e-9c74-224fd16cda46"
      },
      "source": [
        "first_round = total_dataset(price_data, gt_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count 0\n",
            "is_it_calc?\n",
            "count 1\n",
            "is_it_calc?\n",
            "count 2\n",
            "is_it_calc?\n",
            "count 3\n",
            "is_it_calc?\n",
            "count 4\n",
            "is_it_calc?\n",
            "count 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuFZqagPc2cW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6dc91508-3564-4a40-a061-d8957a331c42"
      },
      "source": [
        "dataset = get_dataset(price_data,4,gt_data)\n",
        "predictions = get_results(dataset[0])\n",
        "#actual_income = profit(predictions,dataset[1])\n",
        "#best_income = profit(dataset[1],dataset[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is_it_calc?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d36Alg2Rjs1m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce48c440-30c1-4012-a1c5-e4a74ebe7939"
      },
      "source": [
        "103669.37569486132-118125.99133141339"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-14456.615636552073"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBhHxZOxj-cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1026 companies (NASDAQ) (will be different for NYSE)\n",
        "# 1245 time steps\n",
        "\n",
        "# tickers     (1026,)         : array (string)  \n",
        "#                             - stock symbol\n",
        "# eod_data    (1026, 1245, 5) : array (float32) \n",
        "#                             - features for a given ticker \n",
        "#                               [0] 5-day avg, [1] 10-day avg, [2] 20-day avg, \n",
        "#                               [3] 30-day avg, [4] actual stock price (scaled)\n",
        "# mask_data   (1026, 1245)    : array (float32) \n",
        "#                             - masks, not sure what these do \n",
        "#                               yet. Expected at least one 0 in the position of\n",
        "#                               the stock ticker's index, but they're all 1...\n",
        "# gt_data     (1026, 1245)    : array (float32) \n",
        "#                              - ground truths, change in day to day price\n",
        "# price_data  (1026, 1245)    : array (float32) \n",
        "#                             - actual stock price (scaled), same as eod_data[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQwRX68NdLHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "b69103ba-04d4-474f-ce94-d74071344309"
      },
      "source": [
        "datasets = [tickers, eod_data, mask_data, gt_data, price_data]\n",
        "\n",
        "i = 2 # Apple for NASDAQ, AAP for NYSE\n",
        "for d in datasets:\n",
        "    print(d.shape, d.dtype)\n",
        "    print(d[i], '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1737,) <U5\n",
            "AAP \n",
            "\n",
            "(1737, 1245, 5) float32\n",
            "[[0.357611 0.357296 0.359589 0.367068 0.361763]\n",
            " [0.359497 0.357092 0.359617 0.366186 0.361763]\n",
            " [0.361773 0.357885 0.359971 0.365516 0.367402]\n",
            " ...\n",
            " [0.501996 0.481316 0.457942 0.441529 0.486576]\n",
            " [0.498613 0.485303 0.462484 0.443908 0.487124]\n",
            " [0.499641 0.490832 0.467439 0.446347 0.500599]] \n",
            "\n",
            "(1737, 1245) float32\n",
            "[1. 1. 1. ... 1. 1. 1.] \n",
            "\n",
            "(1737, 1245) float32\n",
            "[ 0.          0.          0.01558752 ... -0.0360843   0.00112625\n",
            "  0.02766242] \n",
            "\n",
            "(1737, 1245) float32\n",
            "[0.361763 0.361763 0.367402 ... 0.486576 0.487124 0.500599] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my9GJyeL1bMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gt_data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihrML0Bwmf9n",
        "colab_type": "text"
      },
      "source": [
        "### Relational Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh94PrUHnk1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "relation_name = 'sector_industry' # 'wikidata' 'sector_industry'\n",
        "emb_fname = 'NASDAQ_rank_lstm_seq-16_unit-64_2.csv.npy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fz2xb8Dmf2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# relation data\n",
        "rname_tail = {'sector_industry': '_industry_relation.npy',\n",
        "              'wikidata': '_wiki_relation.npy'}\n",
        "\n",
        "rel_encoding, rel_mask = load_relation_data(\n",
        "    os.path.join(data_path, '..', 'relation', relation_name,\n",
        "                  market_name + rname_tail[relation_name])\n",
        ")\n",
        "# print('relation encoding shape:', rel_encoding.shape)\n",
        "print('relation mask shape:', rel_mask.shape)\n",
        "\n",
        "embedding = np.load(\n",
        "    os.path.join(data_path, '..', 'pretrain', emb_fname))\n",
        "print('embedding shape:', embedding.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhdhcOS6H-20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rel_datasets = [rel_encoding, rel_mask, embedding]\n",
        "\n",
        "i = 2 # Apple\n",
        "for d in rel_datasets:\n",
        "    print(d.shape, d.dtype)\n",
        "    print(d[i], '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83yWkEKj_sW5",
        "colab_type": "text"
      },
      "source": [
        "# Next Steps\n",
        "\n",
        "- Figure out how to load pretrained weights by reviewing how the TRSR people did it...[link](https://github.com/fulifeng/Temporal_Relational_Stock_Ranking/blob/master/training/relation_rank_lstm.py)\n",
        "- Rewrite the GNN in `pytorch`\n",
        "- Initialize company correlation matrix\n",
        "- Calculate the return baselines (done)\n",
        "  - Best Possible Return: For each time step, find stock with highest return and invest completely in that stock\n",
        "  - Standard Return: If we would have just invested in the full index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNNPKOJH2BTy",
        "colab_type": "text"
      },
      "source": [
        "## Initializing company correlation matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dLne2gYPCmv",
        "colab_type": "text"
      },
      "source": [
        "### Attempt 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv0tBWYMXkGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import pearsonr\n",
        "data = gt_data\n",
        "n = 30\n",
        "from datetime import datetime\n",
        "\n",
        "time_periods = len(gt_data[0])-(n-1)\n",
        "class analysis_object:\n",
        "    def __init__(self, data, n):\n",
        "        self.data = data\n",
        "        self.n = n\n",
        "    def product(self,p):\n",
        "        print(p)\n",
        "        if n < 2:\n",
        "            return []\n",
        "        stock_count = len(self.data)\n",
        "\n",
        "        covariance_tensor = np.zeros((stock_count,stock_count))\n",
        "        #count = 1\n",
        "        for i in range(0,stock_count):\n",
        "            for j in range(i+1,stock_count):\n",
        "                #if ((i*stock_count+j)/(stock_count*stock_count))>0.05*count:\n",
        "                #    clear_output()\n",
        "                #    print(\"We are \"+str(5*count)+\"% done\")\n",
        "                #    count+=1\n",
        "                x = self.data[i][p:(p+self.n)]\n",
        "                y = self.data[j][p:(p+self.n)]\n",
        "                covariance_tensor[i][j] = pearsonr(x,y)[0]\n",
        "        return covariance_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws3xhyRxkx0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = analysis_object(gt_data,30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiFfJTNnk1l-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import concurrent.futures\n",
        "import pickle\n",
        "time_periods = len(gt_data[0])-(30-1)\n",
        "futures = {}\n",
        "company_correlations = {}\n",
        "file_name = 'company_correlations.pkl'\n",
        "with open(file_name, 'wb') as handle:\n",
        "  with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "      for i in range(0,time_periods):\n",
        "          futures[i] = executor.submit(data.product, i)\n",
        "      for k in futures:\n",
        "          company_correlations[k] = futures[k].result()\n",
        "          if k%5 == 1:\n",
        "            pickle.dump(company_correlations, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "print(company_correlations[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GPunK-SoLGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "company_correlations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAPbmZznmftI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to upload the pickled file to google drive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)  \n",
        "\n",
        "# get the folder id where you want to save your file\n",
        "file = drive.CreateFile({'parents':[{u'id': folder_id}]})\n",
        "file.SetContentFile(file_name)\n",
        "file.Upload() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AsnqWeCBA0R",
        "colab_type": "text"
      },
      "source": [
        "### Attempt 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9gMGiPxBNv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import pearsonr\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVjfp79MEFJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# corr tensor\n",
        "corr_size = 30\n",
        "num_companies, num_timesteps = gt_data.shape\n",
        "correlation_matrix_shape = (num_timesteps - corr_size, num_companies, num_companies)\n",
        "corr = np.ones(correlation_matrix_shape)\n",
        "print(corr.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUIcrMrzBNqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for t in tqdm(range(num_timesteps - corr_size)):\n",
        "    for c1 in tqdm(range(num_companies)):\n",
        "        for c2 in range(1, num_companies - c1):\n",
        "            c1_movements = gt_data.T[t:t+corr_size][:,c1]\n",
        "            c2_movements = gt_data.T[t:t+corr_size][:,c1 + c2]\n",
        "            c1_c2_corr = pearsonr(c1_movements, c2_movements)[0]\n",
        "            if np.isnan(c1_c2_corr):\n",
        "                c1_c2_corr = 1e-10\n",
        "            corr[t][c1][c1 + c2] = c1_c2_corr        \n",
        "    corr[t][il] = corr[t][iu]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMfvYh9FlJLT",
        "colab_type": "text"
      },
      "source": [
        "## Calculating Return Baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjfG3cCWlL9y",
        "colab_type": "text"
      },
      "source": [
        "### Optimal\n",
        "The best possible return is calculated by finding the stock with the highest \n",
        "percent increase at each timestep and investing a fixed, non-compounding amount into that one stock per timestep.\n",
        "\n",
        "| skip_n_steps | NASDAQ | NYSE |\n",
        "|---|---|---|\n",
        "| 0 | 20102.418 | 16884.516 | \n",
        "| 30 | 19622.406 | 16482.426 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdIYZCdWlLOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gt_data.shape  # (1026, 1245)\n",
        "best_stock_per_t  = np.argmax(gt_data.T, axis=1) # best stock at each timestep\n",
        "best_return_per_t = np.max(gt_data.T, axis=1) # best return at each timestep\n",
        "\n",
        "print(best_stock_per_t)\n",
        "print(best_return_per_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h72JwbODmEEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_return = 0\n",
        "daily_investment = 100\n",
        "n = 0 # starting point intended to exclude the first n days we don't have correlations for"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fkJnmYWqxhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loop form\n",
        "for r in best_return_per_t[n:]:\n",
        "    daily_return = (daily_investment * (1.0 + r)) - daily_investment\n",
        "    total_return += daily_return\n",
        "print(total_return)\n",
        "\n",
        "# vector form (more concise, faster)\n",
        "total_return = np.sum(np.multiply(daily_investment, best_return_per_t[n:]))\n",
        "print(total_return)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtwl6YBD5kvj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7f600ffc-0653-401c-fb8c-b94d5691b2dc"
      },
      "source": [
        "def best_return(pct_returns, daily_investment=100, skip_n_steps=0):\n",
        "    return np.sum(np.multiply(daily_investment, np.max(pct_returns.T, axis=1)[skip_n_steps:]))\n",
        "\n",
        "print(best_return(gt_data, 100, 0))\n",
        "print(best_return(gt_data, 100, 30))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16884.516\n",
            "16482.426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DILzjmqrrMgX",
        "colab_type": "text"
      },
      "source": [
        "### Average\n",
        "The average return assumes investing in each stock in the index equally (computed by averaging all the stock returns) and investing a fixed, non-compounding amount at every time step. \n",
        "\n",
        "| skip_n_steps | NASDAQ | NYSE |\n",
        "|---|---|---|\n",
        "| 0 | 57.427822 | 35.447433 | \n",
        "| 30 | 55.723846 | 31.19346 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qun-PnSk4ZMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gt_data.shape  # (1026, 1245)\n",
        "avg_return_per_t = np.average(gt_data.T, axis=1) # avg return at each timestep\n",
        "print(avg_return_per_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SxuHKFm7JYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_return = 0\n",
        "daily_investment = 100\n",
        "n = 0 # starting point intended to exclude the first n days we don't have correlations for"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXtDzaSArWiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loop form\n",
        "for r in avg_return_per_t[n:]:\n",
        "    daily_return = (daily_investment * (1.0 + r)) - daily_investment\n",
        "    total_return += daily_return\n",
        "print(total_return)\n",
        "\n",
        "# vector form (more concise, faster)\n",
        "total_return = np.sum(np.multiply(daily_investment, avg_return_per_t[n:]))\n",
        "print(total_return)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BprnkwPY5IH0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3da9d0b2-003e-4ec7-dda3-9a3e811627bc"
      },
      "source": [
        "def avg_return(pct_returns, daily_investment=100, skip_n_steps=0):\n",
        "    return np.sum(np.multiply(daily_investment, np.average(pct_returns.T, axis=1)[skip_n_steps:]))\n",
        "\n",
        "print(avg_return(gt_data, 100, 0))\n",
        "print(avg_return(gt_data, 100, 30))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35.447433\n",
            "31.19346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewpc_Pmo5jTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8drcKZVT55p9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a0d2428-58b7-4094-9eaa-d95657c9292b"
      },
      "source": [
        "time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1592256866.6780775"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKryBBVQRZeg",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch Examples\n",
        "\n",
        "Here are some examples of how to make custom models in Pytorch to get you started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "behCcoyZTha9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    print('CUDA is available!')\n",
        "    device = torch.device(\"cuda\")\n",
        "    use_cuda = True\n",
        "else:\n",
        "    print('CUDA is not available.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CMHc01PXnfG",
        "colab_type": "text"
      },
      "source": [
        "### Define Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMRH7VobS2_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FCNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dens1 = nn.Linear(784, 256)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.drop1 = nn.Dropout(0.2)\n",
        "        self.dens2 = nn.Linear(256, 128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.drop2 = nn.Dropout(0.2)\n",
        "        self.dens3 = nn.Linear(128, 64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.drop3 = nn.Dropout(0.2)\n",
        "        self.dens4 = nn.Linear(64, 20)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.drop4 = nn.Dropout(0.2)\n",
        "        self.dens5 = nn.Linear(20, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dens1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.drop1(x)\n",
        "        x = self.dens2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.drop2(x)\n",
        "        x = self.dens3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.drop3(x)\n",
        "        x = self.dens4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.drop4(x)\n",
        "        x = self.dens5(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class Conv2DNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4 * 4 * 50)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCndeWlYXwfm",
        "colab_type": "text"
      },
      "source": [
        "### Define Training and Testing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oPfg1yHS0dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # calculate robust loss\n",
        "        loss = F.cross_entropy(model(data), target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            batch_size = len(data)\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                       100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    acc = 100. * correct / len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset), acc))\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM43F_EKXzSU",
        "colab_type": "text"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Sedz5GUC8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"/content/data/\"\n",
        "batch_size_train = 10\n",
        "batch_size_test = 10\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(data_dir, train=True, download=True,\n",
        "                         transform=torchvision.transforms.Compose([\n",
        "                           torchvision.transforms.ToTensor()\n",
        "                         ])),\n",
        "    batch_size=batch_size_test, shuffle=False, pin_memory=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(data_dir, train=False, download=True,\n",
        "                         transform=torchvision.transforms.Compose([\n",
        "                           torchvision.transforms.ToTensor()\n",
        "                         ])),\n",
        "    batch_size=batch_size_test, shuffle=False, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgyFQL0dX1Iz",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pmvMsouMKC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPYoau_9MKAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rel_encoding = (torch.ones((100)) * np.arange(100)).view(10,10).unsqueeze_(-1)\n",
        "rel_shape = rel_encoding.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23qXqWhsMJ-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25402b8d-5a3a-4ac8-e202-53eb5583e4e4"
      },
      "source": [
        "rel_mask = torch.where(rel_encoding == 0, torch.ones(rel_shape) * -1e9, torch.zeros(rel_shape)).squeeze_()\n",
        "rel_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ku6Cj9OUXUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 10\n",
        "\n",
        "fcnet5 = FCNet5().to(device)\n",
        "conv2dnet = Conv2DNet().to(device)\n",
        "\n",
        "for model in [fcnet5, conv2dnet]:\n",
        "    \n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "    m_type = model.__class__.__name__\n",
        "    \n",
        "    print('training for model', m_type)\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train(model, device, train_loader, optimizer, epoch)\n",
        "        acc = test(model, device, test_loader)  \n",
        "\n",
        "    # torch.save(model.state_dict(), save_dir + 'model_' + m_type + '_' + str(datetime.date.today()) + '_' + str(acc) + '.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gkLRcR3Utj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "# hyper-parameters\n",
        "BATCH_SIZE = 128\n",
        "LR = 0.01\n",
        "GAMMA = 0.90\n",
        "EPISILO = 0.9\n",
        "MEMORY_CAPACITY = 20000\n",
        "Q_NETWORK_ITERATION = 100\n",
        "\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "env = env.unwrapped\n",
        "NUM_ACTIONS = env.action_space.n\n",
        "NUM_STATES = env.observation_space.shape[0]\n",
        "ENV_A_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample.shape\n",
        "class Net(nn.Module):\n",
        "    \"\"\"docstring for Net\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(NUM_STATES, 50)\n",
        "        self.fc1.weight.data.normal_(0,0.1)\n",
        "        self.fc2 = nn.Linear(50,30)\n",
        "        self.fc2.weight.data.normal_(0,0.1)\n",
        "        self.out = nn.Linear(30,NUM_ACTIONS)\n",
        "        self.out.weight.data.normal_(0,0.1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        action_prob = self.out(x)\n",
        "        return action_prob\n",
        "\n",
        "class DQN():\n",
        "    \"\"\"docstring for DQN\"\"\"\n",
        "    def __init__(self):\n",
        "        super(DQN, self).__init__()\n",
        "        self.eval_net, self.target_net = Net(), Net()\n",
        "\n",
        "        self.learn_step_counter = 0\n",
        "        self.memory_counter = 0\n",
        "        self.memory = np.zeros((MEMORY_CAPACITY, NUM_STATES * 2 + 2))\n",
        "        # why the NUM_STATE*2 +2\n",
        "        # When we store the memory, we put the state, action, reward and next_state in the memory\n",
        "        # here reward and action is a number, state is a ndarray\n",
        "        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR)\n",
        "        self.loss_func = nn.MSELoss()\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        state = torch.unsqueeze(torch.FloatTensor(state), 0) # get a 1D array\n",
        "        if np.random.randn() <= EPISILO:# greedy policy\n",
        "            action_value = self.eval_net.forward(state)\n",
        "            action = torch.max(action_value, 1)[1].data.numpy()\n",
        "            action = action[0] if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)\n",
        "        else: # random policy\n",
        "            action = np.random.randint(0,NUM_ACTIONS)\n",
        "            action = action if ENV_A_SHAPE ==0 else action.reshape(ENV_A_SHAPE)\n",
        "        return action\n",
        "\n",
        "\n",
        "    def store_transition(self, state, action, reward, next_state):\n",
        "        transition = np.hstack((state, [action, reward], next_state))\n",
        "        index = self.memory_counter % MEMORY_CAPACITY\n",
        "        self.memory[index, :] = transition\n",
        "        self.memory_counter += 1\n",
        "\n",
        "\n",
        "    def learn(self):\n",
        "\n",
        "        #update the parameters\n",
        "        if self.learn_step_counter % Q_NETWORK_ITERATION ==0:\n",
        "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
        "        self.learn_step_counter+=1\n",
        "\n",
        "        #sample batch from memory\n",
        "        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)\n",
        "        batch_memory = self.memory[sample_index, :]\n",
        "        batch_state = torch.FloatTensor(batch_memory[:, :NUM_STATES])\n",
        "        batch_action = torch.LongTensor(batch_memory[:, NUM_STATES:NUM_STATES+1].astype(int))\n",
        "        batch_reward = torch.FloatTensor(batch_memory[:, NUM_STATES+1:NUM_STATES+2])\n",
        "        batch_next_state = torch.FloatTensor(batch_memory[:,-NUM_STATES:])\n",
        "\n",
        "        #q_eval\n",
        "        q_eval = self.eval_net(batch_state).gather(1, batch_action)\n",
        "        q_next = self.target_net(batch_next_state).detach()\n",
        "        q_target = batch_reward + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)\n",
        "        loss = self.loss_func(q_eval, q_target)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "def main():\n",
        "    dqn = DQN()\n",
        "    episodes = 400\n",
        "    print(\"Collecting Experience....\")\n",
        "    for i in range(episodes):\n",
        "        state = env.reset()\n",
        "        ep_reward = 0\n",
        "        while True:\n",
        "            env.render()\n",
        "            action = dqn.choose_action(state)\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "\n",
        "            dqn.store_transition(state, action, reward, next_state)\n",
        "            ep_reward += reward\n",
        "\n",
        "            if dqn.memory_counter >= MEMORY_CAPACITY:\n",
        "                dqn.learn()\n",
        "                if done:\n",
        "                    print(\"episode: {} , the episode reward is {}\".format(i, round(ep_reward, 3)))\n",
        "            if done:\n",
        "                break\n",
        "            state = next_state\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHM3gKXBgbxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
